"""
ğŸ¨ Self-Hosted Kilim Motif Generator v2 â€” SDXL Turbo (CPU)
Daha kaliteli image generation â€” SDXL tabanlÄ±, 2-5dk/image
"""
import os
import io
import base64
import time
import logging
from contextlib import asynccontextmanager

from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional
from PIL import Image, ImageFilter, ImageOps

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("image-gen")

MODEL_DIR = os.environ.get("MODEL_DIR", "/models")
MODEL_ID = os.environ.get("MODEL_ID", "stabilityai/sdxl-turbo")
NUM_THREADS = int(os.environ.get("NUM_THREADS", "0"))
PORT = int(os.environ.get("PORT", "8080"))

# Global pipelines
pipe_t2i = None
pipe_i2i = None
model_ready = False

KILIM_PROMPT = """masterpiece, best quality, professional traditional Anatolian Turkish kilim carpet motif, 
highly detailed geometric folk art pattern, pixel-perfect stepped lines, diamond shapes, 
triangle borders, zigzag edges, elibelinde motif style, 
rich deep crimson red, royal navy blue, antique gold saffron, natural cream ivory wool, dark walnut brown, 
textured woven wool fabric surface, visible thread weave pattern, slight raised embossed relief texture,
authentic hand-woven kilim aesthetic, tactile textile feel,
symmetric composition, ornate decorative kilim border frame, museum quality Turkish rug design,
close-up macro photography of a real kilim rug showing fabric texture"""

NEGATIVE_PROMPT = """blurry, low quality, deformed, ugly, disfigured, photorealistic person, face, 
3d render, modern art, abstract expressionism, 
watercolor, oil painting, pencil sketch, cartoon, anime,
text, watermark, signature, logo"""


def load_model():
    """SDXL Turbo model yÃ¼kle"""
    global pipe_t2i, pipe_i2i, model_ready
    import torch
    from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image

    logger.info(f"ğŸ“¦ Model yÃ¼kleniyor: {MODEL_ID}")
    logger.info(f"ğŸ“‚ Cache dizini: {MODEL_DIR}")
    start = time.time()

    if NUM_THREADS > 0:
        torch.set_num_threads(NUM_THREADS)
        logger.info(f"ğŸ§µ Thread sayÄ±sÄ±: {NUM_THREADS}")
    else:
        logger.info(f"ğŸ§µ Thread sayÄ±sÄ±: otomatik ({torch.get_num_threads()})")

    # SDXL Turbo â€” text-to-image
    pipe_t2i = AutoPipelineForText2Image.from_pretrained(
        MODEL_ID,
        torch_dtype=torch.float32,
        cache_dir=MODEL_DIR,
        variant="fp16" if torch.cuda.is_available() else None,
        safety_checker=None,
    )

    # SDXL Turbo â€” img2img (model aÄŸÄ±rlÄ±klarÄ±nÄ± paylaÅŸÄ±r)
    pipe_i2i = AutoPipelineForImage2Image.from_pipe(pipe_t2i)

    elapsed = time.time() - start
    model_ready = True
    logger.info(f"âœ… SDXL Turbo model hazÄ±r! ({elapsed:.1f}s)")


@asynccontextmanager
async def lifespan(app: FastAPI):
    load_model()
    yield


app = FastAPI(title="Kilim Motif Generator v2 â€” SDXL Turbo", lifespan=lifespan)


class GenerateRequest(BaseModel):
    prompt: Optional[str] = None
    image: Optional[str] = None
    strength: float = 0.55            # orijinal deseni %45 koru
    steps: int = 6            # SDXL Turbo: strength*steps >= 4 olmalÄ±
    guidance_scale: float = 0.0   # SDXL Turbo: 0.0 = en iyi
    width: int = 512
    height: int = 512


def preprocess_drawing(img: Image.Image, size: int = 512) -> Image.Image:
    """
    Minimal preprocessing â€” orijinal Ã§izimi koru, sadece resize et.
    SDXL Turbo strength=0.65 ile orijinal ÅŸekli koruyup kilim stili uygulayacak.
    """
    return img.resize((size, size), Image.LANCZOS)


def add_emboss_texture(img: Image.Image) -> Image.Image:
    """
    GerÃ§ek halÄ± dokuma tekstÃ¼rÃ¼ â€” prosedÃ¼rel iplik Ã¶rÃ¼ntÃ¼sÃ¼ overlay.
    Yatay ve dikey iplik Ã§izgileri oluÅŸturup multiply blend ile bindirir.
    """
    from PIL import ImageEnhance, ImageDraw
    import numpy as np

    w, h = img.size

    # Dokuma tekstÃ¼r pattern oluÅŸtur â€” gri tonlarda
    texture = Image.new("L", (w, h), 200)
    draw = ImageDraw.Draw(texture)

    # Yatay iplik Ã§izgileri (kilim atkÄ± iplikleri)
    for y in range(0, h, 4):
        brightness = 160 if (y // 4) % 2 == 0 else 220
        draw.line([(0, y), (w, y)], fill=brightness, width=1)
        draw.line([(0, y + 1), (w, y + 1)], fill=brightness - 30, width=1)

    # Dikey iplik Ã§izgileri (kilim Ã§Ã¶zgÃ¼ iplikleri) â€” daha ince
    for x in range(0, w, 6):
        brightness = 180 if (x // 6) % 2 == 0 else 210
        draw.line([(x, 0), (x, h)], fill=brightness, width=1)

    # Texture'Ä± RGB'ye Ã§evir
    texture_rgb = Image.merge("RGB", [texture, texture, texture])

    # Multiply blend â€” orijinal renkleri koruyarak doku ekle
    import numpy as np
    img_arr = np.array(img, dtype=np.float32)
    tex_arr = np.array(texture_rgb, dtype=np.float32)

    # Multiply: (img * texture) / 255
    result_arr = (img_arr * tex_arr) / 255.0

    # Orijinal ile karÄ±ÅŸtÄ±r â€” %35 doku efekti
    blended_arr = img_arr * 0.65 + result_arr * 0.35
    blended_arr = np.clip(blended_arr, 0, 255).astype(np.uint8)

    result = Image.fromarray(blended_arr)

    # Hafif kontrast artÄ±r
    enhancer = ImageEnhance.Contrast(result)
    result = enhancer.enhance(1.15)

    # Sharpen â€” iplik detaylarÄ± belirginleÅŸtir
    result = result.filter(ImageFilter.SHARPEN)

    return result


@app.post("/generate")
def generate(req: GenerateRequest):
    """Image generation â€” text2img veya img2img"""
    if not model_ready:
        return {"error": "Model henÃ¼z yÃ¼klenmiyor"}, 503

    prompt = req.prompt or KILIM_PROMPT
    start = time.time()

    try:
        if req.image:
            logger.info(f"ğŸ–¼ï¸ img2img baÅŸlÄ±yor (strength={req.strength}, steps={req.steps})")
            img_data = req.image.split(",")[1] if "," in req.image else req.image
            input_img = Image.open(io.BytesIO(base64.b64decode(img_data))).convert("RGB")

            # Preprocessing
            processed_img = preprocess_drawing(input_img, req.width)
            logger.info("ğŸ¨ Preprocessing tamamlandÄ±")

            result = pipe_i2i(
                prompt=prompt,
                image=processed_img,
                num_inference_steps=req.steps,
                guidance_scale=req.guidance_scale,
                strength=req.strength,
            )
        else:
            logger.info(f"âœï¸ text2img baÅŸlÄ±yor (steps={req.steps})")
            result = pipe_t2i(
                prompt=prompt,
                num_inference_steps=req.steps,
                guidance_scale=req.guidance_scale,
                width=req.width,
                height=req.height,
            )

        output_img = result.images[0]

        # Kabartma/emboss efekti â€” gerÃ§ek halÄ± dokusu hissi
        output_img = add_emboss_texture(output_img)

        buf = io.BytesIO()
        output_img.save(buf, format="PNG")
        b64 = base64.b64encode(buf.getvalue()).decode()

        elapsed = time.time() - start
        logger.info(f"âœ… Image Ã¼retildi ({elapsed:.1f}s)")

        return {
            "image": f"data:image/png;base64,{b64}",
            "elapsed_seconds": round(elapsed, 1),
        }

    except Exception as e:
        logger.error(f"âŒ Generation hatasÄ±: {e}")
        return {"error": str(e)}, 500


@app.get("/health")
def health():
    import torch
    return {
        "status": "ready" if model_ready else "loading",
        "model": MODEL_ID,
        "threads": torch.get_num_threads() if model_ready else None,
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)
